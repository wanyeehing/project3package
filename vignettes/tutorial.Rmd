---
title: "Project 3: project3package Tutorial"
author: "Wan Yee Hing"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{project3package Tutorial}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Introduction

In Statistics, we talk a lot about statistical inference and prediction. So, we
introduce **project3package** here to provide some functions to handle
statistical inference and statistical prediction. Specifically,
**project3package** provides four functions:
* my_t.test function
* my_lm function
* my_knn_cv function
* my_rf_cv function

To install **project3package**, use the following code:
```{r install, eval = FALSE}
devtools::install_github("wanyeehing/project3package")
```

To begin, we load the **project3package**.
```{r setup}
library(project3package)
library(ggplot2)
```

In this tutorial, I will be using data from `gapminder` and `palmerpenguins`
package to demonstrate the functions.

## Tutorial for my_t.test

Now, I will demonstrate on how to use the my_t.test function provided in
**project3package**.

In this section, we are going to use the `lifeExp` data from `my_gapminder`,
so we need to run the following line of code.
```{r}
life_exp <- my_gapminder$lifeExp
```

First of all, let us see how to test the hypothesis:
$$
H_0: \mu = 60,\\
H_a: \mu \neq 60.
$$

To do it, we call the `my_t.test` function using the following way:
(Note that we use "two.sided" as the alternative as our alternative hypothesis
is $\mu \neq 60$)
```{r}
my_t.test(life_exp, alternative = "two.sided", mu = 60)
```

By looking at the result given by the function, we can see that the p-value we
get in this hypothesis testing is
`r round(my_t.test(life_exp, alternative = "two.sided", mu = 60)$p_val, 3)`. The
p-value we get is greater than our cut-off $\alpha = 0.05$. So, we conclude
that we do not have enough evidence to reject the null hypothesis that
$\mu = 60$.

Next, let us take a look on how to test another hypothesis:
$$
H_0: \mu = 60,\\
H_a: \mu < 60.
$$

In this case, the alternative hypothesis have the $<$ sign, so we will use
"less" as the alternative when using the `my_t.test` function.
```{r}
my_t.test(life_exp, alternative = "less", mu = 60)
```

From this test, we also notice that our p-value,
`r round(my_t.test(life_exp, alternative = "less", mu = 60)$p_val, 3)` is
greater than $\alpha = 0.05$. Therefore, we also fail to reject the null
hypothesis that $\mu = 60$.

For the last case where the alternative hypothesis have the $>$ sign,
$$
H_0: \mu = 60,\\
H_a: \mu > 60.
$$
we will use the following code:

```{r}
my_t.test(life_exp, alternative = "greater", mu = 60)
```

In the last case, we see that the p-value is
`r round(my_t.test(life_exp, alternative = "greater", mu = 60)$p_val, 3)`.
This p-value is less than $\alpha = 0.05$, so we have enough evidence to
reject the null hypothesis, $\mu = 60$.

## Tutorial for my_lm

In this section, I will demonstrate the usage of `my_lm` function. Here, we will
do a regression using `lifeExp` as the response variable and `gdpPercap` and
`continent` as the explanatory variables.

```{r}
regression <- my_lm(lifeExp ~ gdpPercap + continent, data = my_gapminder)
regression
```

From the regression, we get a `gdpPercap` coefficient of `r regression[2, 1]`.
This value tells us that for every 1 scale increase in `gdpPercap`, the
`lifeExp` increase by `r regression[2, 1]`.

The call give a t-value of `r regression[2, 3]` to gdpPercap.

```{r}
gdp_est <- regression[, 1]
x <- model.matrix(lifeExp ~ gdpPercap + continent, data = my_gapminder)
fitted <- x %*% gdp_est
plot_df <- data.frame("actual" = my_gapminder$gdpPercap,
                      "fitted" = fitted,
                      "continent" = my_gapminder$continent)
ggplot(plot_df, aes(x = fitted, y = actual, color = continent)) + geom_point()
```

**still not done yet**

## Tutorial for my_knn_cv

In this section, we will be looking at the `my_knn_cv` function. It is a
function that performs k-nearest neighbors cross-validation. In this tutorial,
we will be using data from `my_penguins`.

Because the `my_penguins` data consists of some `NA` values, we need to clean
them out:
```{r}
clean <- na.omit(my_penguins)
```

Then, we determine the train and test that we are going to use in the function.
Since we are going to predict output class `species` using covariates
`bill_length_mm`, `bill_depth_mm`, `flipper_length_mm`, and `body_mass_g`, we
will run the following lines of code:
```{r}
train_knn <- clean[, c("bill_length_mm", "bill_depth_mm", "flipper_length_mm",
                   "body_mass_g")]
test_knn <- clean$species
```

Since we are going to iterate through `k_nn` from 1 to 10, we first create empty
lists to store the training misclassification rates and CV misclassification
rates.
```{r}
trn_err <- c()
cv_err <- c()
```

After that, we iterate through `k_nn` from 1 to 10 using `k_cv = 5` in the
`my_lm` function and record the training misclassification rates and CV
misclassification rates inside.
```{r}
for (i in 1:10) {
  my_knn <- my_knn_cv(train = train_knn, cl = test_knn, k_nn = i, k_cv = 5)
  cv_err[i] <- my_knn$cv_err
  trn_err[i] <- mean(my_knn$class != test_knn)
}
```

**explain on the remaining bullet points**
